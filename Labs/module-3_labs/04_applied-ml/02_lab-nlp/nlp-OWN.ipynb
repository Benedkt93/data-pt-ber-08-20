{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\broth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\broth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\broth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kittycat = 'We are all agreeing with the cats on this one, and she is too!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are all agreeing with the cats on this one and she is too\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_up(text):\n",
    "    import re\n",
    "    text = re.sub('[^A-Za-z0-9 ]','',text)\n",
    "    #we take out everything that is not a letter, number or a whitespace and replace it by an empty string\n",
    "    text = text.lower().strip()\n",
    "    #makes everything in text lower and replaces whitepsaces at the beginning and at the end\n",
    "    return text\n",
    "kittycat_clean = clean_up(kittycat)\n",
    "print(kittycat_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'all', 'agreeing', 'with', 'the', 'cats', 'on', 'this', 'one', 'and', 'she', 'is', 'too']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "kittycat_tokenize = word_tokenize(kittycat_clean)\n",
    "print(kittycat_tokenize)\n",
    "#splits up string in list of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitten'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example:\n",
    "lemmatizer.lemmatize(\"kittens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example:\n",
    "lemmatizer.lemmatize(\"goes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'all', 'agreeing', 'with', 'the', 'cat', 'on', 'this', 'one', 'and', 'she', 'is', 'too']\n"
     ]
    }
   ],
   "source": [
    "kittycat_lemmatize = [lemmatizer.lemmatize(item) for item in kittycat_tokenize]\n",
    "print(kittycat_lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example \n",
    "stemmer.stem(\"going\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'all', 'agre', 'with', 'the', 'cat', 'on', 'this', 'one', 'and', 'she', 'is', 'too']\n"
     ]
    }
   ],
   "source": [
    "kittycat_stem = [stemmer.stem(item) for item in kittycat_lemmatize]\n",
    "print(kittycat_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agre', 'cat', 'one']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "\n",
    "kittycat_nostopwords = [item for item in kittycat_stem if not item in stopwords_list]\n",
    "print(kittycat_nostopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit_transform(kittycat_nostopwords).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying to real data: IMDB movie reviews\n",
    "\n",
    "Get the data from here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "An example walkthrough: https://dropsofai.com/sentiment-analysis-with-python-bag-of-words/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Large Movie Review Dataset v1.0\n",
    "\n",
    "Overview\n",
    "\n",
    "This dataset contains movie reviews along with their associated binary\n",
    "sentiment polarity labels. It is intended to serve as a benchmark for\n",
    "sentiment classification. \n",
    "\n",
    "Dataset \n",
    "\n",
    "The core dataset contains 50,000 reviews split evenly into 25k train\n",
    "and 25k test sets. The overall distribution of labels is balanced (25k\n",
    "pos and 25k neg). We also include an additional 50,000 unlabeled\n",
    "documents for unsupervised learning. \n",
    "\n",
    "In the labeled train/test sets, a negative review has a score <= 4 out of 10,\n",
    "and a positive review has a score >= 7 out of 10. Thus reviews with\n",
    "more neutral ratings are not included in the train/test sets. In the\n",
    "unsupervised set, reviews of any rating are included and there are an\n",
    "even number of reviews > 5 and <= 5.\n",
    "\n",
    "Files\n",
    "\n",
    "There are two top-level directories [train/, test/] corresponding to\n",
    "the training and test sets. Each contains [pos/, neg/] directories for\n",
    "the reviews with binary labels positive and negative. Within these\n",
    "directories, reviews are stored in text files named following the\n",
    "convention [[id]_[rating].txt] where [id] is a unique id and [rating] is\n",
    "the star rating for that review on a 1-10 scale. For example, the file\n",
    "[test/pos/200_8.txt] is the text for a positive-labeled test set\n",
    "example with unique id 200 and star rating 8/10 from IMDb. The\n",
    "[train/unsup/] directory has 0 for all ratings because the ratings are\n",
    "omitted for this portion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# reading positive reviews\n",
    "txt_folder = Path('aclImdb/train/pos').rglob('*.txt')\n",
    "files = [x for x in txt_folder]\n",
    "content = []\n",
    "for name in files:\n",
    "    f = open(name, 'r')  \n",
    "    content.append(f.readlines()[0])\n",
    "    f.close()\n",
    "pos = pd.DataFrame(content)\n",
    "pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading negative reviews\n",
    "txt_folder = Path('aclImdb/train/neg').rglob('*.txt')\n",
    "files = [x for x in txt_folder]\n",
    "content = []\n",
    "for name in files:\n",
    "    f = open(name, 'r')  \n",
    "    content.append(f.readlines()[0])\n",
    "    f.close()\n",
    "neg = pd.DataFrame(content)\n",
    "neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will try to predict whether a review is positive\n",
    "pos['target'] = 1\n",
    "neg['target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting both dataframes together\n",
    "df = pd.concat([pos, neg], axis = 0)\n",
    "df.rename(columns = {0:'review'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset is very large, so we are only taking a subset for analysis\n",
    "df = df.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_clean'] = df['review'].apply(clean_up)\n",
    "df.head()\n",
    "#apply to apply the functions on a row-wise basis; apply is used for dataframes when map is used for lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "df['review_tokenize'] = df['review_clean'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['review_lemmatize'] = df['review_tokenize'].apply(lambda row: [lemmatizer.lemmatize(item) for item in row])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "df['review_stem'] = df['review_lemmatize'].apply(lambda row: [stemmer.stem(item) for item in row])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "\n",
    "df['review_nostopwords'] = df['review_stem'].apply(lambda row: [item for item in row if not item in stopwords_list])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "\n",
    "#(analyzer=lambda x: x) to apply it directly to whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['review_nostopwords']).toarray()\n",
    "# one line for every list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['target'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(precision_score(y_test, pred))\n",
    "print(recall_score(y_test, pred))\n",
    "print(f1_score(y_test, pred))\n",
    "\n",
    "# all variables are pretty similar, because dataset as classes are balanced\n",
    "# usually we have unbalanced datasets and we are doing well for majority classes and bad for minority ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
